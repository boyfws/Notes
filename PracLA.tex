
\documentclass{article}

% Packages
\usepackage{amsmath}
\usepackage{enumitem} % Для настройки списков
\usepackage{amssymb} % Подключаем пакет для знака следствия
\usepackage[utf8]{inputenc}
\usepackage[russian]{babel}
\usepackage{array}
\usepackage{tikzexternal}
\usepackage{translit}


\allowdisplaybreaks


\title{Практическая линейная алгебра}
\author{Минкин Даниэль}

% Document
\begin{document}
    \maketitle

    \tableofcontents % Оглавление

    \section{Введение}

    \subsection{Темы}

    Вот ключевые темы курса:

    \begin{itemize}
        \item Псевдообратная матрица
        \item Линейная регрессия и МНК
        \item Полиномиальная интерполяция, сплайны, кривые Безье (возможно сплайны Безье)
        \item Аппроксимация (лишь часть связанная с лин. алгеброй) (Многочлены Чебышева)
        \item Метрики и нормы
        \item Оценка погрешности стандартных задач линейной алгебры
        \item Итерационные алгоритмы
        \item Проблемы собственных значений и собственных векторов
        \item Неотрицательные и положительные матрицы и их специальные свойства (Теорема Фробениуса — Перрона). Пример использования данной теоремы --- RageRank
        \item Функции от матриц
        \item (Если успеем) Системы алгебраических уравнений
        \item (Если успеем) Линейные экономические модели
    \end{itemize}

    \quad

    В процессе также будут затронуты:

    \quad

    \begin{itemize}
        \item Разложения матриц
        \item Приближение малого ранга (a.k.a PCA в общем виде)
    \end{itemize}

    \subsection{Организация курса}

    Будет 2 онлайн кр (как на выч. стате дают сложные задачи на подумать) в конце каждого из модулей. 
    Формула оценки задается как: 
    
    \begin{equation}
       0.5 \cdot \text{КР1} + 0.5 \cdot \text{КР2} + \text{Бонус}
    \end{equation}

    Бонус будет формироваться в зависимсоти от активности на парах, НО основная его часть будет получена за формирование доклада по линейной алгебре, который будет презентован на одной из пар.

    \textbf{Чел упомянул интересную тему для доклада: существует теорема, по которой мы с помощью двух линейных слоев и функции активации можно аппроксимировать любую функцию с заданной точностью}


    \section{Разложение полного ранга (скелетное разложение)}

    Пусть $A$ матрица $(m, n)$, такая что $\operatorname{rang}(A) = r$.
    Разложение $A = FG$, где $F$ имеет размерность $(m, r)$, а $G$ имеет размерность $(r, n)$ называется
    разложением полного ранга.

    Заметим, что $\operatorname{rang}(F) <= r$ из-за размера, при этом $\operatorname{rang}(F) >= r$ по свойству умножения матриц.
    Следовательно $\operatorname{rang}(F) = r$, это матрица полного столбцового ранга, аналогично получаем, что $G$ матрица полного строкового ранга.
    Таким образом матрица $A$ представима, как произведение двух полнорангвых матриц

    \subsection{Теорема о существовани скелетеного разложения}

    Для любой матрицы существуют скелетное разложение

    \quad

    \textbf{Доказательство}

    \quad

    Покажем, что для любой матрицы существует скелетное разложение,
    у нас есть $r$ независимых столбцов внутри матрицы.
    Выберем первые $r$ столбцов (мы можем так сделать так, как нам не важно какие брать, остальные точно могут быть выражены через них ),
    тогда матрица $A$ представима как
    $A = (\bar{a}_{1} \ ... \ \bar{a}_{r} \ \sum^{r}_{i = 1}{w_{1, i}  \bar{a}_{i}} \ ... \  \sum^{r}_{i = 1}{w_{n - r, i} \bar{a}_{i}})$.
    Пусть тогда матрица $F$ равна $(\bar{a}_{1} \ ... \ \bar{a}_{r})$, она имеет размер $(m, r)$.
    По условию отбора данных столбцов они все линейно независимы, таким образом $\operatorname{rang}(F) = r$, так как
    $\operatorname{rang}(F) <= r$ (по условию размера матрицы) и при этом $\operatorname{rang}(F) >= r$ (так как все столбцы ЛНЗ).

    Рассмотрим матрицу $G$, которая выглядит так $G = (e(1) \ ... \ e(r) \ w_{1} \ ... \ w_{n - r})$, где
    $e(i)$ --- вектор с размерностью $m$ где все координаты равны $0$, а $i$ - ая координата равна 1.
    Такая матрица имеет размерность $(r, n)$ и ее первые $r$ столбцов линейно независимы, а остальные выражаются через них, следовательно
    $\operatorname{rang}(G) = r$.
    При этом $FG = A$.
    Ч.Т.Д

    \subsection{Практический способ нахождения склетного разложения}

    Рассмотрим практический способ нахождения данного разложения.
    Приведем матрицу $A$ с размерами $(m, n)$ к каноническому виду (на диагонали 1, а под ними ничего).
    У нас получится $r$ ступенек, вырежем верхний левый блок канонической матрицы, размером
    $(r, n)$.
    Далее выберем столбцы у которых в каноническом виде в столбце всего лишь одна $1$ и во всех остальных местах нули.
    Добавим эти столбцы в новую матрицу, тогда это будет матрица $F$





    \section{Псевдообратная матрица}
    
    \textbf{Почему мы не можем всегда использовать метод Гаусса для решения СЛАУ?}

    \quad

    Самый большой минус - сложность задаваемая как $O(n ^ {2})$ для квадратной матрицы $n$ на $n$.

    Вторая проблема - аккумуляция погрешности при использовании данного метода, пример: при вычитании первой строчки из второй, ошибка первой строчки суммируется со второй.
    Плюс также погрешность создают float-ы (особенно с первой причиной вместе)

    \quad 

    Вспомним, что такое обратная матрица.
    Это матрица $A^{-1}$ такая, что

    \begin{equation}
        A A^{-1} = A^{-1} A = \operatorname{E}
    \end{equation}

    Пусть матрица $A$ имеет размеры $m$ на $n$, попробуем проверить условия, которыми задаются условия для обратной матрицы

    Тогда $A A^{-1} = \operatorname{E}$, тут $\operatorname{E}$ будет иметь размеры $m$ на $m$, а $A^{-1}$ иметь размеры $n$ на $m$.
    В обратном же случае $A^{-1} A = \operatorname{E}$ матрица $\operatorname{E}$ будет иметь размеры $n$ на $n$.

    Если мы будем использовать лишь одно из условий, тогда очень легко определить обратную матрицу

    \subsection{Немного о ранге}

    $\operatorname{rang}$ может быть определен как

    \begin{itemize}
        \item Наибольшее кол-во линейно независимых строк/столбцов в матрице
        \item $\dim(\operatorname{Im}(A) )$, где $A$ --- наша матрица, а $\operatorname{Im}$ --- образ нашей матрицы.
    \end{itemize}

    \quad

    \textbf{Вспоминаем условие про ранг суммы и произведения}

    \quad

    \textbf{Ранг суммы}

    Рассмотрим выражение $\operatorname{rang}(A + B)$ и попробуем его оценить.
    Очевидно, что $\operatorname{rang}(A + B) <= \operatorname{rang}(A) + \operatorname{rang}(B)$.
    Почему так?
    По свойству линейных операторов можно заметить, что $(A + B)v = Av + Bv$, следовательно,
    любой вектор из $\operatorname{Im}(A + B)$ является подпространством $\operatorname{Im}(A) + \operatorname{Im}(B)$.
    При этом $\operatorname{Im}(A) + \operatorname{Im}(B) = \{u + v | u \in \operatorname{Im}(A), v \in \operatorname{Im}(B)\}$.
    По свойству пространств $\dim(U + V) = \dim(U) + \dim(V) - \dim(U \cap V)$ (Это уже на 100\% интуитивно).
    Следовательно $\dim(U + V) <= \dim(U) + \dim(V)$.
    Применяя данное уравнение к образам, получим $\dim(\operatorname{Im}(A + B)) <= \dim(\operatorname{Im}(A)) + \dim(\operatorname{Im}(B))$,
    что исходя из определения $\operatorname{rang}$ приводит к $\operatorname{rang}(A + B) <= \operatorname{rang}(A) + \operatorname{rang}(B)$.
    Ч.Т.Д

    \quad 
    
    \textbf{Ранг произведения}

    $\operatorname{rang}(AB) <= \max(A, B)$.
    В данном случае посмотрим на суть произведения матриц --- это композиция линейных операторов.
    Т.е функция от функции, сначала применяется линейный оператор $B$, а к результату применяется оператор $A$.
    Пусть $A$ --- матрица $(m, n)$, а $B$ --- матрица $(n, k)$.
    Рассмотрим процесс работы данной композиции, к нам приходит вектор с размерностью $k$, его отображают в пространство с размерностью
    $\operatorname{rang}(B)$, а после к нему применяется оператор $A$, заметим,
    что он не может отобразить вектор в пространство с размерностью больше чем $\operatorname{rang}(B) \Rightarrow
    \operatorname{rang}(AB) <= \operatorname{rang}(B)$, при этом выходная размерность также не может превысить $\operatorname{rang}(A)$.
    Таким образом $\operatorname{rang}(AB) <= \min(\operatorname{rang}(B), \operatorname{rang}(A)) <= \max(\operatorname{rang}(B), \operatorname{rang}(A))$

    \subsection{Снова возврат к псевдообратной матрице}

    \begin{equation}
        \operatorname{rang}(A A^{-1}) = m
    \end{equation}

    \begin{equation}
        \operatorname{rang}(A^{-1} A) = n
    \end{equation}

    При этом $\operatorname{rang}(A) <= \min(m, n)$.
    Исходя из неравенств выше получаем,
    что $\operatorname{rang}(A) >= m$ и $\operatorname{rang}(A) >= n$
    (Так как максимальный элемент из $\operatorname{rang}(A)$ и $\operatorname{rang}(A^{-1})$
    больше данных значений).
    \textbf{Однако в таком случае возникает противоречие, если $m \neq n$}.
    Это говорит о том, что мы не можем использовать такие аксиомы для нашей ``обратной``
    матрицы, которая может быть применена в общем случае


    \subsection{Рассмотрим виды СЛАУ}

    Какие виды систем уравнений бывают:

    \begin{itemize}
        \item \textbf{Определенная} --- у нас есть матрица $(m, n)$, где $m > n$.
        Система имеет единственное решение.
        Мы хотим представить решение как $J b$,
        когда уравнение задается как $Ax = b$, где $J$ --- произвольная матрица с размерами
        $(n, m)$.
        \item \textbf{Не определенная} --- решений бесконечно много.
        У нас возникает вопрос как выразить хоть какое то решение
        \item \textbf{Не совместна} --- решений нет.
        Мы хотим получить наиболее правдоподобное приближение к решению
    \end{itemize}

    \subsection{Эрмитова матрица}

    Введем операцию комплексного (эрмитова) сопряжения для матрицы.
    Пусть дана матрица $A$, тогда эрмитово сопряженная матрица (которая обозначается как $A^{*}$)
    это транспонированная матрица $A$ в которой каждый элемент заменили на комплексно сопряженный ему.
    Т.е для любого $a \in \mathbb{C} \backslash \mathbb{R}$ в матрице $A$ $\overline{a + b i} = a - bi$.
    Новая матрица называется \textbf{эрмитово сопряженной}

    \quad

    \textbf{Эрмитова матрица} --- квадратная матрица, которая при транспонировании равна совей эрмитово сопряженной матрице
    \begin{equation}
        A^{T} = A^{*}
    \end{equation}

    \quad

    \textbf{NOTE:} Любая симметричная матрица является эрмитовой

    \subsection{Наконец то опредлеим псевдообратную матрицу}

    Пусть $A$ --- некая прямоугольная матрица.
    Матрица $C$ называется псевдообратной матрицей (а точнее псевдообратной Мура-Пенроуза),
    если выполняются следующие 4 аксиомы Пенроуза

    \begin{itemize}
        \item $ACA = A$
        \item $CAC = C$
        \item $(AC)^{*} = AC$ (i.e это эрмитова матрица)
        \item $(CA)^{*} = CA$ (тоже эрмитова)
    \end{itemize}

    \quad

    Важные замечания которые следуют из аксиом

    \begin{itemize}
        \item Если $A$ --- матрица $(m, n)$, то $C$ имеет размер $(n, m)$
        \item Если $A$ --- невырожденная квадрантная матрица, то псевдообратная матрица совпадет с обратной матрицей
    \end{itemize}

    \quad

    \textbf{Покажем что данная матрица единственна}

    \quad

    1. Пусть \(B\) и \(C\) — две псевдообратные матрицы для \(A\).
    2. Тогда:
       \[
       B = BAB = B(AC A)B = (BA)(CA)B.
       \]
    3. Поскольку \(BA\) и \(CA\) эрмитовы, их можно переставлять в сопряжённом виде:

        \begin{align*}
        BACAB &= (BA)^* (CA)^* B
              = A^* B^* A^* C^* B
              = (ABA)^* C^* B \\
              &= A^* C^* B
              = (CA)^* BAB
              = CABAB \\
              &= CAB.
        \end{align*}

    4. Аналогично:
       \[
       C = CAC = C(AB A)C = (CA)(BA)C = C A B.
       \]
    5. Из \(B = CAB\) и \(C = CAB\) следует \(B = C\), что доказывает единственность.

    \quad

    \textbf{Введем специальный символ}

    \quad

    Псевдообратную матрицу принято обозначать, как $A^{+}$

    \quad

    \subsection{Немного опредлений}

    \begin{quote}
        Матрица $A$ $(m, n)$ называется \textbf{матрицей полного столбового ранга}, если $\operatorname{rang}(A) = n$.
        При этом $m > n$.
        Т.е все ее столбцы Л.Н.З
    \end{quote}

    \quad

    \begin{quote}
        Матрица $A$ $(m, n)$ называется \textbf{матрицей полного строкового ранга}, если $\operatorname{rang}(A) = m$.
        При этом $m < n$.
        Т.е все ее строки Л.Н.З
    \end{quote}

    \quad

    Вставил не по порядку рассказа чисто по своему желанию:

    \quad

    \begin{quote}
        Вспомним определение ядра: $\ker(A) = \{v | Av = \bar{0} \} $.
        При этом по свойству ядра $\dim(\operatorname{Im}(A)) + \dim(\ker(A)) = n$, для матрицы $(m, n)$
    \end{quote}

    \subsection{Примеры работы}

    \subsubsection{Частный случай}

    Рассмотрим матрицу $(1 \ 1)$.
    Нам нужно найти псевдообратную к ней, мы точно значем, что псевдообратная матрица будет иметь размерность $(2, 1)$.
    Т.е псевдобратная матрица это некий вектор \(\left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right)\).
    Запишем, все аксиомы:

    \begin{itemize}
        \item $(1 \ 1) \left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right) (1 \ 1) = (1 \ 1)$
        \item $\left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right) (1 \ 1) \left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right) = \left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right) $
        \item $((1 \ 1) \left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right))^{*} =  (1 \ 1) \left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right)$
        \item $(\left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right) (1 \ 1))^{*} = \left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right) (1 \ 1)$
    \end{itemize}

    Заметим, что третий пункт всегда выполняется, значит его можно исключить, выполним перемножение матриц

    \begin{itemize}
        \item $(a + b) (1 \ 1) = (1 \ 1)$
        \item $\left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right) (a + b) = \left(\begin{smallmatrix} a \\ b \end{smallmatrix}\right) $
        \item $ \left(\begin{smallmatrix} a & a \\ b & b \end{smallmatrix}\right)^{*} = \left(\begin{smallmatrix} a & a \\ b & b \end{smallmatrix}\right)$
    \end{itemize}

    Следовательно $a = b$ и $a + b = 1$ таким образом псевдообратная матрица имеет вид \(\left(\begin{smallmatrix} 0.5 \\ 0.5 \end{smallmatrix}\right)\)

    \subsubsection{Общий случай}

    В общем случае для вектора $\bar{a}$ псевдообратная матрица будет иметь вид:

    \begin{equation}
        \bar{a}^{+} = \frac{\bar{a}^{*}}{\Vert a \Vert^{2}}
    \end{equation}

    Покажем, что все аксиомы выполняются

    \begin{itemize}
        \item $  \bar{a} \frac{\bar{a}^{*}}{\Vert a \Vert^{2}} \bar{a}   =  \bar{a}$
        \item $\frac{\bar{a}^{*}}{\Vert a \Vert^{2}} \bar{a} \frac{\bar{a}^{*}}{\Vert a \Vert^{2}} = \frac{\bar{a}^{*}}{\Vert a \Vert^{2}}$
        \item $(\bar{a} \frac{\bar{a}^{*}}{\Vert a \Vert^{2}})^{*} = \bar{a} \frac{\bar{a}^{*}}{\Vert a \Vert^{2}}$
        \item $( \frac{\bar{a}^{*}}{\Vert a \Vert^{2}} \bar{a})^{*} = \frac{\bar{a}^{*}}{\Vert a \Vert^{2}} \bar{a}$
    \end{itemize}

    Это равносильно
    (Note: для расчета нормы комплексного вектора используется не транспонирование, а комплексное сопряжение)

    \begin{itemize}
        \item $  \bar{a} \cdot 1 =  \bar{a}$
        \item $1 \cdot \frac{\bar{a}^{*}}{\Vert a \Vert^{2}} = \frac{\bar{a}^{*}}{\Vert a \Vert^{2}}$
        \item $(\bar{a} \frac{\bar{a}^{*}}{\Vert a \Vert^{2}})^{*} = \bar{a} \frac{\bar{a}^{*}}{\Vert a \Vert^{2}}$
        \item $1^{*} = 1$
    \end{itemize}

    Таким образом нам нужно, чтобы выполнялось выражение

    \begin{equation}
        (\bar{a} \frac{\bar{a}^{*}}{\Vert a \Vert^{2}})^{*} = \bar{a} \frac{\bar{a}^{*}}{\Vert a \Vert^{2}}
    \end{equation}

    Сократим константу

    \begin{equation}
        (\bar{a} \bar{a}^{*})^{*} = \bar{a} \bar{a}^{*}
    \end{equation}

    Раскроем эрмитово сопряжение

    \begin{equation}
        \bar{a} \bar{a}^{*} = \bar{a} \bar{a}^{*}
    \end{equation}

    Следовательно, аксиома 3 тоже выполняется.
    А по условию единственности это и есть псевдообратная матрица, легко показать, что для вектора строки ситуация будет аналогичной

    \subsection{Лемма об обратимости $A^{*} A$}

    Пусть $A$ --- матрица полного столбцового ранга, то матрица $A^{*} A$ --- невырожденная квадрантная матрица.
    (Для матрицы полного строкового ранга все практически 1 в 1 сейм)

    \quad

    \textbf{Доказательство}

    Пусть $A$ --- матрица $(m, n)$, такая, что $n < m$ и $\operatorname{rang}(A) = n$.
    Заметим, что $\operatorname{rang}(A^{*} A) <= \operatorname{rang}(A)$ (по свойству произведения матриц).
    Тогда для док-ва нам достаточно показать, что $\operatorname{rang}(A^{*} A) >= \operatorname{rang}(A)$.
    По свойству ядра, если $X$ имеет размерность $(m, n)$, то $\dim(\ker(X)) + \operatorname{rang}(X) = n$.
    Пусть $x \in \ker(A^{*} A)$, тогда $A^{*} A x = 0$, домножим на $x^{*}$ справа, тогда выражение примет вид
    $(Ax)^{*} Ax = 0$.
    Это скалярное произведение вектора $Ax$ на самого себя и по свойству скалярного произведения мы получаем, что
    $Ax = 0$, при этом $\dim(\ker(A)) = 0$, следовательно $\dim(\ker(A^{*} A)) = 0$, а тогда $\operatorname{rang}(A^{*} A) = n$

    В общем случае мы доказали, что $\ker(A^{*} A) \subset \ker(A) $, отсюда вытекает неравенство
    $\dim(\ker(A^{*} A)) <= \dim(\ker(A))$, то равносильно $n - \operatorname{rang}(A^{*} A) <= n - \operatorname{rang}(A)$, что приводит нас к
    $\operatorname{rang}(A^{*} A) >= \operatorname{rang}(A)$
    
    \quad
    
    \subsection{Теорема о существовании псевдообратной матрицы для матриц полного столб. и строч. ранга}

    Если $A$ матрица $(m, n)$, такая что $n < m$ и что $\operatorname{rang}(A) = n$ (матрица полного столбцового ранга), то $A^{+}$ существует
    и равна

    \begin{equation}
        A^{+} = (A^{*} A)^{-1} A ^{*}
    \end{equation}

    Для матрицы полного строчного ранга

    \begin{equation}
        A^{+} = A^{*} (A A ^{*})^{-1}
    \end{equation}

    Проверим аксиомы для матрицы полного столбцового ранга

    \begin{itemize}
        \item $A (A^{*} A)^{-1} A ^{*} A = A$
        \item $(A^{*} A)^{-1} A ^{*} A (A^{*} A)^{-1} A ^{*} = (A^{*} A)^{-1} A ^{*}$
        \item $(A (A^{*} A)^{-1} A ^{*})^{*} = A (A^{*} A)^{-1} A ^{*}$
        \item $((A^{*} A)^{-1} A ^{*}A)^{*} = (A^{*} A)^{-1} A ^{*}A$
    \end{itemize}

    Это сводится к
    (3 точно выполняется)

    \begin{itemize}
        \item $A E = A$
        \item $(A^{*} A)^{-1} E A ^{*} = (A^{*} A)^{-1} A ^{*}$
        \item $(E)^{*} = E$
    \end{itemize}

    Следовательно, данная матрица удовлетворяет всем четырем аксиомам и единственна

    \textbf{Аналогично, для матриц полного строчного ранга}


    \subsection{Теорема о существовании псевдообратной матрицы для любой матрицы}

    \subsubsection{Лемма об обратной матрице произвдения матриц}

    Если $A = BC$, где $B$ --- матрица полного столбцового ранга,
    а $C$ --- матрица полного строкового ранга, то тогда $A^{+} = B^{+} C^{+}$,

    \quad

    \textbf{Доказательство}

    \quad

    Рассмотрим, аксиомы для $A$, пусть псевдообратнная матрица $A^{+} = C^{+} B^{+} $, если для нее будут выполнены аксиомы,
    то тогда по условию единственности, это и есть псевдообртаная матрица

    \begin{itemize}
        \item $A C^{+} B^{+} A = A$
        \item $C^{+} B^{+} A C^{+} B^{+} = C^{+} B^{+}$
        \item $(A C^{+} B^{+})^{*} = AC^{+} B^{+}$
        \item $(C^{+} B^{+} A)^{*} = C^{+} B^{+}A$
    \end{itemize}

    Заменим $A$ на $BC$, тогда

    \begin{itemize}
        \item $BC C^{+} B^{+} BC = BC$
        \item $C^{+} B^{+} BC C^{+} B^{+} = C^{+} B^{+}$
        \item $(BC C^{+} B^{+})^{*} = BCC^{+} B^{+}$
        \item $(C^{+} B^{+} BC)^{*} = C^{+} B^{+}BC$
    \end{itemize}

    Так как мы знаем, что за матрицы $B$ и $C$ мы можем выразить их псведообратные матрицы явно

    \begin{itemize}
        \item $BC ( C^{*} (C C ^{*})^{-1} ) ( (B^{*} B)^{-1} B^{*} ) BC = BC$
        \item $(C^{*} (C C ^{*})^{-1}) ( (B^{*} B)^{-1} B^{*} ) BC (C^{*} (C C ^{*})^{-1}) ( (B^{*} B)^{-1} B^{*}) = (C^{*} (C C ^{*})^{-1})( (B^{*} B)^{-1} B^{*})$
        \item $(BC (C^{*} (C C ^{*})^{-1}) ((B^{*} B)^{-1} B^{*}))^{*} = BC (C^{*} (C C ^{*})^{-1}) ((B^{*} B)^{-1} B^{*})$
        \item $((C^{*} (C C ^{*})^{-1}) ( (B^{*} B)^{-1} B^{*}) BC)^{*} = (C^{*} (C C ^{*})^{-1}) ( (B^{*} B)^{-1} B^{*}) BC$
    \end{itemize}

    Начнем раскрывать скобки

    \begin{itemize}
        \item $B C = BC$
        \item $(C^{*} (C C ^{*})^{-1})  ( (B^{*} B)^{-1} B^{*}) = (C^{*} (C C ^{*})^{-1})( (B^{*} B)^{-1} B^{*})$
        \item $(B ((B^{*} B)^{-1} B^{*}))^{*} = B (B^{*} B)^{-1} B^{*}$
        \item $((C^{*} (C C ^{*})^{-1}) C)^{*} = (C^{*} (C C ^{*})^{-1}) C$
    \end{itemize}

    Легко заметить, что все 4 аксиомы выполняются

    \subsubsection{Основная теорема}

    Для любой матрицы существует псевдообратная матрица

    \quad

    \subsubsection{Начало доказательства}

    \quad

    Мы знаем, что такая матрица есть для невырожденных матриц,
    матриц полного столбцового и строкового рангов и нулевых матриц,
    рассмотрим ситуацию для других матриц, которые не попадают в эту категорию.
    Мы знаем, что для любой матрицы можно применить скелетное разложение, так и сделаем для произвольной матрицы
    $A$, тогда $A = FG$, по свойству леммы о произведении матриц мы знаем, что $A^{+} = G^{+} F^{+}$.
    При этом, мы знаем, что для любой матрицы полного столбцового ранга и полного строчного ранга, существует псвдообратная матрица,
    следовательно $A^{+} = G^{*} (G G ^{*})^{-1} (F^{*} F)^{-1} F ^{*}$.
    Следовательно, для любой матрицы существует псевдообратная.
    
    \subsection{Суть псевдообратной матрицы}

    В случае несовместных систем псевдообратная матрица позволяет получить наиболее точное приближенное решение по МНК.
    Сформулируем задачу более точно.
    Вектор $\bar{u}$ называется приближенным решением системы $A \bar{x} = \bar{b}$ по МНК или псевдорешением, если для любого $\bar{x}$ выполняется

    \begin{equation}
        \Vert A \bar{x} - \bar{b} \Vert \geq \Vert A \bar{u} - \bar{b} \Vert
    \end{equation}

    Используется Евклидова норма, легко заметить, что если система имеет решение, то оно совпадает с псевдорешением
    
    \subsection{Теорема о псевдорешении}

    Вектор $\bar{u} = A^{+} \bar{b}$ является псевдорешением и 
    имеет наименьшую длину из всех псевдорешений 

    \quad

    \textbf{Доказательство}

    \quad

    Заметим, что $\operatorname{Im}(A)$ порождено столбцами матрицы $A$, а все векторы $\ker(A)$ ортогональны строкам матрицы $A$.
    Следовательно для любых $\bar{x} \in \operatorname{Im}(A)$ и $\bar{y} \in \ker(A^{*})$ выполняется $\bar{x} \cdot \bar{y} = 0$.
    Аналогично и в обратную сторону для $\bar{x} \in \operatorname{Im}(A^{*})$ и $\bar{y} \in \ker(A)$

    \subsubsection{Лемма}

    Для любого $\bar{x} \in \operatorname{Im}(M)$ и $\bar{y} \in \operatorname{Im}(A)$,
    выполняется $\bar{x} \cdot \bar{y} = 0$, если $M = A A^{+} - E$


    \quad

    \textbf{Доказательство}

    \quad

    Если мы покажем, что $\operatorname{Im}(M) \subset \ker(A^{*})$,
    тогда точно лемма будет доказана по свойству выше.
    Рассмотрим вектор $y = Mx \in \operatorname{Im}(M)$, покажем, что $A^{*}y = 0$.
    $A^{*}Mx = 0$, следовательно $(A^{*} A A^{+} - A^{*}) x = 0$.
    По аксиоме три $(A^{*} (A A^{+})^{*} - A^{*}) x = 0$.
    Это равняется $((A A^{+} A)^{*} - A^{*}) x = 0$.
    Что приводится к $( A^{*} - A^{*}) x = 0$.
    Таким образом данное равенство выполняется всегда. \textbf{Ч.Т.Д}


    \subsubsection{Возврат к доказательству}

    Если $\bar{x} \cdot \bar{y} = 0$, то тогда для $\bar{z} = \bar{x} + \bar{y}$
    выполняется следующее равенство $\Vert \bar{z} \Vert^{2} = \Vert \bar{x} \Vert^{2} + \Vert \bar{y} \Vert^{2}$.
    Покажем это $\Vert \bar{z} \Vert = \sqrt{\bar{z} \cdot \bar{z}}$, раскрывая это получим:
    $\sqrt{(\bar{x} + \bar{y}) \cdot (\bar{x} + \bar{y})}$, что приводит нас к выражению $\sqrt{ \bar{x} \cdot \bar{x} + \bar{y} \cdot \bar{y} }$.
    Следовательно мы получаем, что $\Vert \bar{z} \Vert^{2} = \Vert \bar{x} \Vert^{2} + \Vert \bar{y} \Vert^{2}$. Ч.Т.Д

    Отсюда мы получаем неравенство: $\Vert \bar{z} \Vert \geq \Vert \bar{x} \Vert$ (или $\bar{y}$)

    \quad 

    Покажем, что $u = A^{+} b$ является псевдорешением. Рассмотрим 
    $f(x) = Ax - b$ нам нужно показать, что такой вектор имеет длину больше 
    чем $AA^{+}b - b$. Мы можем заметить, что второе выражние равно 
    $(AA^{+} - E)b$. A $Ax \in \operatorname{Im}(A)$, следовательно 
    эти два вектора перпендикулярны.

    Мы можем записать $f(x)$ как $Ax - Au + Au - b$, 
    где $u = A^{+} b$

    \begin{equation}
        Ax - Au + Au - b = A(x - u) + (AA^{+} - E) b
    \end{equation}

    Легко увидеть, что данные слагаемые перпендикулярны, таким 
    образом исходя из неравенства выше 

    \begin{equation}
       \Vert A(x - u) + (AA^{+} - E) b \Vert \geq \Vert (AA^{+} - E) b \Vert
    \end{equation}

    Раскрывая скобки получим, что для любого $x$ 

    \begin{equation}
        \Vert f(x) \Vert \geq \Vert AA^{+}b - b \Vert
    \end{equation}

    Легко заметить, что равенство достигается при 

    \begin{equation}
        A(x - A^{+}b ) = 0
    \end{equation}

    \quad 

    \textbf{Покажем, что такое решение имеет минимальную длину по сравнению с другими 
    псевдорешениями} 

    \quad 

    Пусть $x$ другое псевдорешение, т.е $A(x - u) = 0$

    Покажем, что $ (x - u) \perp u$, при условии $A(x - u) = 0$.
    Рассмотрим их произвдение

    \begin{equation}
        (x - u)^{*} \cdot u = b^{*} {A^{+}}^{*} (x - u)
    \end{equation}

    При этом ${A^{+}}^{*} = (A^{+} A A^{+})^{*} = {A^{+}}^{*} {A^{+} A}^{*}$. 
    Итого мы получаем, что скалярное произвдение имеет вид 

    \begin{equation}
        b^{*} {A^{+}}^{*} A^{+} A (x - u) = 0
    \end{equation}

    \text{Ч.Т.Д}

    Используя прошлое неравенство мы получим, что 

    \begin{equation}
        \Vert x - u + u \Vert \geq \Vert u \Vert 
    \end{equation}

    Мы доказали, что псевдорешение $A^{+} b$ имеет минимальную длину 
    среди всех возможных 

    \subsubsection{Как описать все псевдорешения?}

    Все псевдорешения могут быть описаны формулой 
    
    \begin{equation}
        A (x - A^{+}b) = 0 
    \end{equation}
    
    Можно заметить, что, если 

    \begin{equation}
        x = A^{+}b - (A^{+}A - E) y
    \end{equation}
    где $y$ --- это произвольный вектор, то тогда подставив такой $x$ в формулу 
    мы получим, что 

    \begin{equation}
        A (A^{+}b - (A^{+}A - E) y - A^{+}b) = - A (A^{+}A - E) y = - (A - A) y = 0
    \end{equation}

    Следовательно любой такой вектор подходит в качестве псевдорешения, т.е минимизирует норму между 
    собой и целевым вектором

    \section{Матричные разложения}

    \subsection{LU разложение}

    $LU$ разложение позволяет представить матрицу как произведение 
    двух матриц $L$ --- нижнетреугольная матрица с единицами на диагонали, а $U$ - верхнетреугольная 

    \subsubsection{Теорема об $LU$ разложении}

    Пусть $A$ --- матрица $(n, n)$ и все угловые подматрицы невырождены.
    Тогда существует единсвтенное разложение $A = LU$, где $L$ --- нижнетреугольная 
    с единицами на диагонали, а $U$ --- верхнетреугольная матрица 

    \quad 

    \textbf{Доказательство}

    \quad 

    Докажем по индукции, что такое разложение существует, база индукции выглядит так: для матрицы $(1, 1)$ мы получим
    $L = \left(\begin{smallmatrix} 1 \end{smallmatrix}\right)$ и $U = \left(\begin{smallmatrix} a_{11} \end{smallmatrix}\right)$

    \quad 

    Пусть разложение существует для любой матрицы размерами $(n - 1, n - 1)$ для которой выполнены требования, 
    покажем что в таком случае оно существует для любой матрицы $A$ с размерами $(n, n)$. Представим $A$ в блочном виде

    \begin{equation}
        A = \begin{bmatrix}
            A_{11} & a_{12} \\ a_{21} & a_{nn}
        \end{bmatrix}
    \end{equation}

    Тут матрица $A_{11}$ имеет размеры $(n - 1, n - 1)$ по условию все угловые миноры ненулевые, следовательно для данной подматрицы сущесвтвует 
    $LU$ разложение $A_{11} = L_{11}U_{11}$

    Мы хотим представить $A$ как $LU$, рассмотрим как должны 
    выглядеть такие матрицы в предположении, что $L$ и $U$ будут занимать соответсвующие им блоки  

    \begin{equation}
        L = \begin{bmatrix}
            L_{11} & 0 \\
            l_{21} & 1
        \end{bmatrix}
    \end{equation}

    и 

    \begin{equation}
        U = \begin{bmatrix}
            U_{11} & u_{12} \\ 
            0 & u_{nn}
        \end{bmatrix}
    \end{equation}

    Тогда произведение матриц задается как 

    \begin{equation}
        LU = \begin{bmatrix}
            L_{11} U_{11} & L_{11} u_{12} \\ 
            l_{21} U_{11} & l_{21} u_{12} + u_{nn}
        \end{bmatrix}
    \end{equation}

    Нужно заметить, что $l_{12}$ --- вектор строка

    \quad

    Запишем наши равенства 

    \[
    \begin{cases}
    L_{11} u_{12} = a_{12} \\
    l_{21} U_{11} = a_{21} \\
    l_{21} u_{12} + u_{nn} = a_{nn}
    \end{cases}
    \]
    Тут $l_{12}$ --- вектор строка и $u_{12}$ --- вектор столбец

    \quad

    $L_{11}$ однозначно обратима, а $U_{11}$ так как все угловые миноры неотрицатльны ($\det(A_{11}) = \det(L_{11}) \cdot \det(U_{11})$
    и при этом $\det(A_{11}) \neq 0$)

    \[
    \begin{cases}
    u_{12} = L_{11}^{-1} a_{12} \\
    l_{21} = a_{21} U_{11}^{-1} \\
    u_{nn} = a_{nn} - a_{21} U_{11}^{-1}L_{11}^{-1} a_{12} = a_{nn} - a_{21} A_{11}^{-1} a_{12} 
    \end{cases}
    \]

    Мы можем заметить, что такое разложение единственно, и для него строго необходимо, чтобы матрица в левом верхнем блоке обращалась

    \subsubsection{Практический подход для LU разложения}

    Мы можем привести матрицу $A$ к нижнетреугольному виду с помощью метода Гаусса, а после найти $U$ как $U = L^{-1}A$


    \subsubsection{Где используется}

    Можно выделить следующие use-case: 

    \begin{itemize}
        \item Быстрое решение систем вида $Ax = y$. Такая система превращается в две треугольные системы при ее представлении как: $LUx = y$    
        \item Численно стабильное решение задачи нахождения $\det$, так как мы можем использовать натуральный логарифм от 
        детерминанта и при этом сохранять численную стабильность решения, так как $\det(A) = \det(L) \cdot \det(U) = 1 \cdot \prod_{i}^{n} U_{ii}$  
        \item Более удобное обращение раскладываемой матрицы
    \end{itemize}

    \subsection{LUP-разложение}

    Данное разложение является обобщением $LU$ разложения на случай любой квадратной невырожденной матрицы. Любая матрица может быть представлена в виде: 

    \begin{equation}
        PA = LU
    \end{equation}

    Т.е мы выполняем разложение для матрицы $PA$, где $P$ отвчеает за перестановку строк в матрице $A$. Мы всегда можем привести невырожденную матрицу $A$ к такому виду, чтобы 
    к ней можно было применить $LU$ разложение, это следует из метода окаймляющих миноров для определения ранга.

    Хорошим алгоритмом для $LUP$ разложения является алгоритм Дулиттла (рассмотрим позже), который позоляет удобно векторизовать вычисления. 
    Однако алгоритмическая сложность все также составляет $O(n^{3})$
 










\end{document}